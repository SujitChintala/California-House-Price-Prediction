{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1498f9bd",
   "metadata": {},
   "source": [
    "# YouTube Trending Videos Analysis & Recommendation System\n",
    "\n",
    "This notebook provides a comprehensive analysis of YouTube trending videos data from multiple countries and builds an intelligent video recommendation system.\n",
    "\n",
    "## Contents\n",
    "1. Data Loading & Merging\n",
    "2. Data Cleaning & Preprocessing\n",
    "3. Exploratory Data Analysis\n",
    "4. Advanced Visualizations\n",
    "5. Recommendation System\n",
    "6. Interactive Frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd23823",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Machine Learning and NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Interactive widgets\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0823014",
   "metadata": {},
   "source": [
    "## 2. Load and Merge CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files\n",
    "print(\"Loading YouTube data from multiple countries...\\n\")\n",
    "\n",
    "ca_data = pd.read_csv('data/CAvideos.csv')\n",
    "gb_data = pd.read_csv('data/GBvideos.csv')\n",
    "in_data = pd.read_csv('data/INvideos.csv')\n",
    "us_data = pd.read_csv('data/USvideos.csv')\n",
    "\n",
    "# Add country identifier\n",
    "ca_data['country'] = 'CA'\n",
    "gb_data['country'] = 'GB'\n",
    "in_data['country'] = 'IN'\n",
    "us_data['country'] = 'US'\n",
    "\n",
    "print(f\"CA Videos: {len(ca_data):,} rows\")\n",
    "print(f\"GB Videos: {len(gb_data):,} rows\")\n",
    "print(f\"IN Videos: {len(in_data):,} rows\")\n",
    "print(f\"US Videos: {len(us_data):,} rows\")\n",
    "\n",
    "# Merge all datasets\n",
    "df = pd.concat([ca_data, gb_data, in_data, us_data], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úì Total merged dataset: {len(df):,} rows\")\n",
    "print(f\"‚úì Columns: {len(df.columns)}\")\n",
    "\n",
    "# Save merged data\n",
    "df.to_csv('data/merged_youtube_data.csv', index=False)\n",
    "print(\"\\n‚úì Merged data saved to 'data/merged_youtube_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc900e",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5554c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf5e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df['tags'] = df['tags'].fillna('')\n",
    "df['description'] = df['description'].fillna('')\n",
    "\n",
    "# Remove duplicates based on video_id\n",
    "original_len = len(df)\n",
    "df = df.drop_duplicates(subset=['video_id'], keep='first')\n",
    "print(f\"Removed {original_len - len(df):,} duplicate videos\")\n",
    "\n",
    "# Clean tags (remove pipe separators)\n",
    "df['tags'] = df['tags'].apply(lambda x: x.replace('|', ' ') if isinstance(x, str) else '')\n",
    "\n",
    "# Convert publish_time to datetime\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')\n",
    "df['publish_date'] = df['publish_time'].dt.date\n",
    "df['publish_hour'] = df['publish_time'].dt.hour\n",
    "\n",
    "# Create engagement metrics\n",
    "df['engagement_score'] = (df['likes'] + df['comment_count'] * 2 - df['dislikes']) / (df['views'] + 1)\n",
    "df['like_ratio'] = df['likes'] / (df['likes'] + df['dislikes'] + 1)\n",
    "df['comment_ratio'] = df['comment_count'] / (df['views'] + 1)\n",
    "\n",
    "print(f\"\\n‚úì Data cleaned! Final dataset: {len(df):,} unique videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f5116",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"=\" * 80)\n",
    "print(\"YOUTUBE TRENDING VIDEOS - STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìä Total Videos: {len(df):,}\")\n",
    "print(f\"üé¨ Unique Channels: {df['channel_title'].nunique():,}\")\n",
    "print(f\"üåç Countries: {df['country'].nunique()}\")\n",
    "print(f\"üìÇ Categories: {df['category_id'].nunique()}\")\n",
    "print(f\"\\nüìà Total Views: {df['views'].sum():,.0f}\")\n",
    "print(f\"üëç Total Likes: {df['likes'].sum():,.0f}\")\n",
    "print(f\"üí¨ Total Comments: {df['comment_count'].sum():,.0f}\")\n",
    "\n",
    "print(f\"\\nüìä Average Statistics per Video:\")\n",
    "print(f\"  Views: {df['views'].mean():,.0f}\")\n",
    "print(f\"  Likes: {df['likes'].mean():,.0f}\")\n",
    "print(f\"  Dislikes: {df['dislikes'].mean():,.0f}\")\n",
    "print(f\"  Comments: {df['comment_count'].mean():,.0f}\")\n",
    "print(f\"  Engagement Score: {df['engagement_score'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5dc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most viewed videos\n",
    "print(\"\\nüî• TOP 10 MOST VIEWED VIDEOS\")\n",
    "print(\"=\" * 80)\n",
    "top_videos = df.nlargest(10, 'views')[['title', 'channel_title', 'views', 'likes', 'country']]\n",
    "for idx, row in top_videos.iterrows():\n",
    "    print(f\"\\n{row['title'][:70]}...\")\n",
    "    print(f\"  Channel: {row['channel_title']} | Country: {row['country']}\")\n",
    "    print(f\"  Views: {row['views']:,} | Likes: {row['likes']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486af38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-wise distribution\n",
    "country_stats = df.groupby('country').agg({\n",
    "    'video_id': 'count',\n",
    "    'views': 'sum',\n",
    "    'likes': 'sum',\n",
    "    'comment_count': 'sum'\n",
    "}).round(0)\n",
    "\n",
    "country_stats.columns = ['Videos', 'Total Views', 'Total Likes', 'Total Comments']\n",
    "print(\"\\nüåç COUNTRY-WISE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(country_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f5daf",
   "metadata": {},
   "source": [
    "## 5. Data Visualizations\n",
    "\n",
    "Let's create comprehensive and informative visualizations to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e750ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Views Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(np.log10(df['views'] + 1), bins=50, color='#FF6B6B', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Log10(Views)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribution of Video Views (Log Scale)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot by country\n",
    "df.boxplot(column='views', by='country', ax=axes[1], patch_artist=True)\n",
    "axes[1].set_xlabel('Country', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Views', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Views Distribution by Country', fontsize=14, fontweight='bold')\n",
    "axes[1].set_yscale('log')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Engagement Metrics Comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Likes vs Views\n",
    "axes[0, 0].scatter(np.log10(df['views'] + 1), np.log10(df['likes'] + 1), \n",
    "                   alpha=0.3, c='#4ECDC4', s=10)\n",
    "axes[0, 0].set_xlabel('Log10(Views)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Log10(Likes)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Likes vs Views Relationship', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Comments vs Views\n",
    "axes[0, 1].scatter(np.log10(df['views'] + 1), np.log10(df['comment_count'] + 1), \n",
    "                   alpha=0.3, c='#FF6B9D', s=10)\n",
    "axes[0, 1].set_xlabel('Log10(Views)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Log10(Comments)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Comments vs Views Relationship', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Engagement Score Distribution\n",
    "axes[1, 0].hist(df['engagement_score'], bins=50, color='#95E1D3', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Engagement Score', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Distribution of Engagement Scores', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Like Ratio Distribution\n",
    "axes[1, 1].hist(df['like_ratio'], bins=50, color='#FFE66D', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Like Ratio', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Distribution of Like Ratios', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f695c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Country-wise Performance Analysis\n",
    "country_data = df.groupby('country').agg({\n",
    "    'views': 'sum',\n",
    "    'likes': 'sum',\n",
    "    'comment_count': 'sum',\n",
    "    'video_id': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Total Views by Country\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "axes[0, 0].bar(country_data['country'], country_data['views'], color=colors, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Country', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Total Views', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Total Views by Country', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].ticklabel_format(style='plain', axis='y')\n",
    "for i, v in enumerate(country_data['views']):\n",
    "    axes[0, 0].text(i, v, f'{v/1e9:.2f}B', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Total Likes by Country\n",
    "axes[0, 1].bar(country_data['country'], country_data['likes'], color=colors, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Country', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Total Likes', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Total Likes by Country', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(country_data['likes']):\n",
    "    axes[0, 1].text(i, v, f'{v/1e6:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Video Count by Country\n",
    "axes[1, 0].bar(country_data['country'], country_data['video_id'], color=colors, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Country', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Number of Videos', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Video Count by Country', fontsize=14, fontweight='bold')\n",
    "for i, v in enumerate(country_data['video_id']):\n",
    "    axes[1, 0].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart - Country Distribution\n",
    "axes[1, 1].pie(country_data['video_id'], labels=country_data['country'], autopct='%1.1f%%',\n",
    "               colors=colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1, 1].set_title('Video Distribution by Country', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13911f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Top Categories Analysis\n",
    "category_stats = df.groupby('category_id').agg({\n",
    "    'video_id': 'count',\n",
    "    'views': 'mean',\n",
    "    'likes': 'mean'\n",
    "}).sort_values('video_id', ascending=False).head(10)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top categories by video count\n",
    "axes[0].barh(category_stats.index.astype(str), category_stats['video_id'], \n",
    "             color='#FF6B6B', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('Number of Videos', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Category ID', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Top 10 Categories by Video Count', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Average views by category\n",
    "top_view_cats = df.groupby('category_id')['views'].mean().sort_values(ascending=False).head(10)\n",
    "axes[1].barh(top_view_cats.index.astype(str), top_view_cats.values, \n",
    "             color='#4ECDC4', edgecolor='black', alpha=0.8)\n",
    "axes[1].set_xlabel('Average Views', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Category ID', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Top 10 Categories by Average Views', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Publishing Time Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Videos by Hour of Day\n",
    "hour_counts = df['publish_hour'].value_counts().sort_index()\n",
    "axes[0].plot(hour_counts.index, hour_counts.values, marker='o', linewidth=2, \n",
    "             markersize=8, color='#FF6B6B')\n",
    "axes[0].fill_between(hour_counts.index, hour_counts.values, alpha=0.3, color='#FF6B6B')\n",
    "axes[0].set_xlabel('Hour of Day', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Videos', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Video Publishing Pattern by Hour', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Average views by hour\n",
    "hour_views = df.groupby('publish_hour')['views'].mean()\n",
    "axes[1].bar(hour_views.index, hour_views.values, color='#4ECDC4', edgecolor='black', alpha=0.8)\n",
    "axes[1].set_xlabel('Hour of Day', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Average Views', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Average Views by Publishing Hour', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(range(0, 24, 2))\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Correlation Heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = ['views', 'likes', 'dislikes', 'comment_count', 'engagement_score', 'like_ratio']\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=2, cbar_kws={\"shrink\": 0.8},\n",
    "            annot_kws={'fontsize': 11, 'fontweight': 'bold'})\n",
    "\n",
    "plt.title('Correlation Matrix of Video Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(fontsize=11, fontweight='bold')\n",
    "plt.yticks(fontsize=11, fontweight='bold', rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b26b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Word Cloud from Video Titles\n",
    "print(\"Generating Word Cloud from Video Titles...\")\n",
    "\n",
    "# Combine all titles\n",
    "all_titles = ' '.join(df['title'].astype(str).values)\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud = WordCloud(width=1600, height=800, background_color='white', \n",
    "                      colormap='viridis', max_words=100, \n",
    "                      relative_scaling=0.5, min_font_size=10).generate(all_titles)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most Common Words in Video Titles', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Word cloud generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8516d",
   "metadata": {},
   "source": [
    "## 6. Build Video Recommendation System\n",
    "\n",
    "Now let's build a content-based recommendation system using TF-IDF and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for recommendation\n",
    "print(\"Building recommendation system...\")\n",
    "\n",
    "# Combine text features\n",
    "df['combined_features'] = (\n",
    "    df['title'].fillna('') + ' ' + \n",
    "    df['tags'] + ' ' + \n",
    "    df['channel_title'].fillna('') + ' ' +\n",
    "    df['description'].apply(lambda x: str(x)[:200] if pd.notna(x) else '')\n",
    ")\n",
    "\n",
    "# Calculate popularity score\n",
    "df['popularity_score'] = (\n",
    "    np.log1p(df['views']) * 0.4 +\n",
    "    np.log1p(df['likes']) * 0.3 +\n",
    "    np.log1p(df['comment_count']) * 0.3\n",
    ")\n",
    "\n",
    "print(\"‚úì Features prepared!\")\n",
    "print(f\"‚úì Dataset size: {len(df):,} videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF Matrix\n",
    "print(\"Creating TF-IDF matrix...\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
    "\n",
    "print(f\"‚úì TF-IDF matrix created!\")\n",
    "print(f\"  Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  Features: {len(tfidf.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def get_video_recommendations(video_id=None, title=None, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Get video recommendations based on video_id or title\n",
    "    \"\"\"\n",
    "    # Find video index\n",
    "    if video_id:\n",
    "        idx = df[df['video_id'] == video_id].index\n",
    "    elif title:\n",
    "        idx = df[df['title'].str.contains(title, case=False, na=False)].index\n",
    "    else:\n",
    "        print(\"‚ùå Please provide either video_id or title\")\n",
    "        return None\n",
    "    \n",
    "    if len(idx) == 0:\n",
    "        print(\"‚ùå Video not found!\")\n",
    "        return None\n",
    "    \n",
    "    idx = idx[0]\n",
    "    \n",
    "    # Get the video details\n",
    "    video = df.iloc[idx]\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìπ SELECTED VIDEO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Title: {video['title']}\")\n",
    "    print(f\"Channel: {video['channel_title']}\")\n",
    "    print(f\"Views: {video['views']:,} | Likes: {video['likes']:,} | Comments: {video['comment_count']:,}\")\n",
    "    print(f\"Country: {video['country']} | Category: {video['category_id']}\")\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx:idx+1], tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get similar video indices\n",
    "    similar_indices = cosine_sim.argsort()[::-1][1:n_recommendations+1]\n",
    "    \n",
    "    # Create recommendations dataframe\n",
    "    recommendations = df.iloc[similar_indices][['title', 'channel_title', 'views', \n",
    "                                                  'likes', 'comment_count', 'country', \n",
    "                                                  'category_id']].copy()\n",
    "    recommendations['similarity_score'] = cosine_sim[similar_indices]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéØ TOP {n_recommendations} RECOMMENDATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, (idx, row) in enumerate(recommendations.iterrows(), 1):\n",
    "        print(f\"\\n{i}. {row['title'][:70]}...\")\n",
    "        print(f\"   Channel: {row['channel_title']}\")\n",
    "        print(f\"   Views: {row['views']:,} | Likes: {row['likes']:,} | Country: {row['country']}\")\n",
    "        print(f\"   Similarity: {row['similarity_score']:.4f}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"‚úì Recommendation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080075c",
   "metadata": {},
   "source": [
    "## 7. Test the Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a popular video\n",
    "test_video_id = df.nlargest(1, 'views').iloc[0]['video_id']\n",
    "recommendations = get_video_recommendations(video_id=test_video_id, n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with search by title\n",
    "recommendations = get_video_recommendations(title='Music', n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88aa290",
   "metadata": {},
   "source": [
    "## 8. Interactive Frontend with Widgets\n",
    "\n",
    "Let's create a simple and clean interactive interface for the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e768ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "def display_recommendations(video_selection, num_recommendations):\n",
    "    \"\"\"Display recommendations in a clean format\"\"\"\n",
    "    output_area.clear_output(wait=True)\n",
    "    \n",
    "    with output_area:\n",
    "        # Get recommendations\n",
    "        if video_selection:\n",
    "            recommendations = get_video_recommendations(\n",
    "                video_id=video_selection, \n",
    "                n_recommendations=num_recommendations\n",
    "            )\n",
    "\n",
    "# Prepare video selection options (top 100 popular videos)\n",
    "popular_videos = df.nlargest(100, 'popularity_score')\n",
    "video_options = {f\"{row['title'][:60]}... ({row['channel_title']})\": row['video_id'] \n",
    "                 for _, row in popular_videos.iterrows()}\n",
    "\n",
    "# Create widgets\n",
    "style = {'description_width': '150px'}\n",
    "\n",
    "video_dropdown = widgets.Dropdown(\n",
    "    options=video_options,\n",
    "    description='Select Video:',\n",
    "    style=style,\n",
    "    layout=widgets.Layout(width='800px')\n",
    ")\n",
    "\n",
    "num_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    description='Recommendations:',\n",
    "    style=style,\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "recommend_button = widgets.Button(\n",
    "    description='üéØ Get Recommendations',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='250px', height='40px'),\n",
    "    style={'font_weight': 'bold'}\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    display_recommendations(video_dropdown.value, num_slider.value)\n",
    "\n",
    "recommend_button.on_click(on_button_click)\n",
    "\n",
    "# Display interface\n",
    "print(\"=\"*80)\n",
    "print(\"üé¨ YOUTUBE VIDEO RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSelect a video from the dropdown and click the button to get recommendations!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML('<h3 style=\"color: #FF0000;\">YouTube Video Recommendation System</h3>'),\n",
    "    widgets.HTML('<p style=\"color: #555;\">Select a video and get personalized recommendations based on content similarity</p>'),\n",
    "    video_dropdown,\n",
    "    num_slider,\n",
    "    recommend_button,\n",
    "    output_area\n",
    "], layout=widgets.Layout(padding='20px', border='2px solid #ddd', border_radius='10px')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c4ad7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "1. ‚úÖ **Merged** four YouTube trending video datasets (CA, GB, IN, US) into a single comprehensive dataset\n",
    "2. ‚úÖ **Cleaned and preprocessed** the data, handling missing values and creating derived metrics\n",
    "3. ‚úÖ **Analyzed** the data with comprehensive statistical summaries\n",
    "4. ‚úÖ **Visualized** the data with informative charts covering:\n",
    "   - View distributions and engagement metrics\n",
    "   - Country-wise performance comparisons\n",
    "   - Category analysis\n",
    "   - Publishing time patterns\n",
    "   - Correlation matrices\n",
    "   - Word clouds\n",
    "5. ‚úÖ **Built** a content-based recommendation system using TF-IDF and cosine similarity\n",
    "6. ‚úÖ **Created** an interactive frontend with widgets for easy video recommendations\n",
    "\n",
    "The recommendation system can suggest similar videos based on title, tags, channel, and description content, helping users discover relevant content!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
